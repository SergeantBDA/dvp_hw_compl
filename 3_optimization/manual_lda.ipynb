{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "* Прочитать про методы оптимизации для нейронных сетей https://habr.com/post/318970/\n",
    "* Реализовать самостоятельно логистическую регрессию\n",
    "    * Обучить ее методом градиентного спуска\n",
    "    * Методом nesterov momentum\n",
    "    * Методом rmsprop\n",
    "* В качестве dataset'а взять Iris, оставив 2 класса:\n",
    "    * Iris Versicolor\n",
    "    * Iris Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Решение \n",
    "\n",
    "[**С П И С А Н О**](https://github.com/ddbourgin/numpy-ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris # Датасет с ирисами\n",
    "from sklearn.model_selection import train_test_split # Метотод разделения выборки на тренировочную и тестовую \n",
    "from sklearn.metrics import roc_curve # построение ROC-кривой (Receiver Operating Characteristic)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Формируем целевой датасет на основе iris\n",
    "iris = load_iris()\n",
    "df_iris = pd.DataFrame( iris['data'], \n",
    "                        columns = [ item.replace(' (cm)', '').replace(' ', '_') for item in iris['feature_names']] )\n",
    "df_iris['variety']      = iris['target']\n",
    "\n",
    "#оставляем только 2 класса 1:versicolor, 2:virginica\n",
    "df_iris_target = df_iris[ (df_iris['variety'].isin([1,2]) ) ]\n",
    "\n",
    "#определяем выборку\n",
    "X = df_iris_target.iloc[:, :-1]\n",
    "y = df_iris_target.iloc[:, -1] - 1 #переводим классы цветов в 0 и 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"img\\formula1.jpg\">\n",
    "<img src = \"img\\formula2.jpg\">\n",
    "<img src = \"img\\formula3.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Опредление сигмоидной функции\n",
    "def sigmoid(x):\n",
    "    \"\"\" Логистическая сигмоидная функция \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, penalty=\"l2\", gamma=0, fit_intercept=True):\n",
    "        r\"\"\"\n",
    "        Пример логистичечкой регрессии с применением в качестве метода обучения градиентного спуска,\n",
    "        функция максимального правдоподобия см. Формулу 1, Формула 2\n",
    "        Функция R - это штраф за регуляризацию.\n",
    "        \n",
    "        N - объем выборки (количество примеров)\n",
    "        betta - вектор коэффициентов модели. \n",
    "        \n",
    "        Параметры\n",
    "        ----------\n",
    "        penalty : {'l1', 'l2'} \n",
    "            Тип регуляризационного штрафа, применяемого к коэффициентам betta. \n",
    "            По умолчанию используется 'l2'\n",
    "        \n",
    "        gamma : float\n",
    "            Вес регуляризации. Большие значения соответствуют большим\n",
    "            штрафы за регуляризацию, а значение 0 указывает на отсутствие штрафа.\n",
    "            По умолчанию 0.\n",
    "        \n",
    "        fit_intercept : bool\n",
    "        Необходимо ли в выбрку добалять первую единицу? #ничего не понятно#\n",
    "        Стоит ли вписываться в дополнение перехват срок коэффициентов в betta. \n",
    "        Если значение равно true, betta будет  'М + 1' габариты, где первое измерение соответствует перехватить. \n",
    "        Значение по умолчанию True.\n",
    "        \"\"\"\n",
    "        err_msg = f\"penalty must be 'l1' or 'l2', but got: {penalty}\"\n",
    "        assert penalty in [\"l2\", \"l1\"], err_msg # тестовые сообщения\n",
    "        self.beta = None # инициализация вектра коэффициентов\n",
    "        self.gamma = gamma\n",
    "        self.penalty = penalty\n",
    "        self.fit_intercept = fit_intercept\n",
    "\n",
    "    def fit(self, X, y, lr=0.01, tol=1e-7, max_iter=1e7):\n",
    "        \"\"\"\n",
    "        Определение коэффициентов регресии методом градиентного спуска.\n",
    "\n",
    "        Параметры\n",
    "        ----------\n",
    "        X : Набор данных (независимые переменные) <numpy.ndarray> \n",
    "        y : Целевые значения (зависимые переменные от X) бинарные данные \n",
    "        lr : float\n",
    "           Скорость обучения градиентному спуску. \n",
    "           По умолчанию 1e-7.\n",
    "           \n",
    "        max_iter : float\n",
    "            Максимальное количество итераций для запуска градиентного спуска. \n",
    "            По умолчанию 1e7.\n",
    "        \"\"\"\n",
    "        # convert X to a design matrix if we're fitting an intercept\n",
    "        if self.fit_intercept:\n",
    "            X = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "        l_prev = np.inf # присвоение +бесконечного значения\n",
    "        self.beta = np.random.rand(X.shape[1]) #инициирование вектора коэф.\n",
    "        for _ in range(int(max_iter)):\n",
    "            y_pred = sigmoid(np.dot(X, self.beta))\n",
    "            loss = self._NLL(X, y, y_pred)\n",
    "            if l_prev - loss < tol:\n",
    "                return\n",
    "            l_prev = loss\n",
    "            self.beta -= lr * self._NLL_grad(X, y, y_pred)\n",
    "\n",
    "    def _NLL(self, X, y, y_pred):\n",
    "        r\"\"\"\n",
    "        Фозвращает значение функции мксимального правдоподобия (см. формула 3)\n",
    "        \"\"\"\n",
    "        N, M = X.shape\n",
    "        beta, gamma = self.beta, self.gamma \n",
    "        order = 2 if self.penalty == \"l2\" else 1\n",
    "        norm_beta = np.linalg.norm(beta, ord=order) # получение нормы матрицы\n",
    "        \n",
    "        nll = -np.log(y_pred[y == 1]).sum() - np.log(1 - y_pred[y == 0] ).sum()\n",
    "        penalty = (gamma / 2) * norm_beta ** 2 if order == 2 else gamma * norm_beta\n",
    "        return (penalty + nll) / N\n",
    "\n",
    "    def _NLL_grad(self, X, y, y_pred):\n",
    "        \"\"\" Градиентный спуск \"\"\"\n",
    "        N, M = X.shape\n",
    "        l1norm = lambda x: np.linalg.norm(x, 1)  # np.max(np.sum(np.abs(x), axis=0)), получение нормы матрицы\n",
    "        p, beta, gamma = self.penalty, self.beta, self.gamma\n",
    "        d_penalty = gamma * beta if p == \"l2\" else gamma * np.sign(beta)\n",
    "        return -( np.dot(y - y_pred, X) + d_penalty ) / N\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Получение данных по обученной модели\n",
    "\n",
    "        Параметры:\n",
    "        X : Независимые переменные\n",
    "\n",
    "        Возвращает:\n",
    "        y_pred : Предсказаные вероятности значений\n",
    "        \"\"\"\n",
    "        # convert X to a design matrix if we're fitting an intercept\n",
    "        if self.fit_intercept:\n",
    "            X = np.c_[np.ones(X.shape[0]), X]\n",
    "        return sigmoid( np.dot(X, self.beta) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "# Разделяем данные на тренировучную и тестовую\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "#Обучаем модель\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вероятность верного предсказания 1 составляет 1.0 \n",
      "Вероятность верного предсказания 1 составляет 0.7733 \n",
      "Вероятность верного предсказания 0 составляет 0.9906 \n",
      "Вероятность верного предсказания 0 составляет 0.9988 \n",
      "Вероятность верного предсказания 0 составляет 0.9237 \n",
      "Вероятность верного предсказания 0 составляет 0.9991 \n",
      "Вероятность верного предсказания 0 составляет 0.9997 \n",
      "Вероятность верного предсказания 0 составляет 0.9984 \n",
      "Вероятность верного предсказания 1 составляет 0.9983 \n",
      "Вероятность верного предсказания 1 составляет 0.6554 \n",
      "Вероятность верного предсказания 1 составляет 0.9999 \n",
      "Вероятность верного предсказания 0 составляет 0.9997 \n",
      "Вероятность верного предсказания 0 составляет 0.9999 \n",
      "Вероятность верного предсказания 0 составляет 0.9999 \n",
      "Вероятность верного предсказания 1 составляет 0.9998 \n",
      "Вероятность верного предсказания 1 составляет 0.999 \n",
      "Вероятность верного предсказания 1 составляет 0.9997 \n",
      "Вероятность верного предсказания 1 составляет 1.0 \n",
      "Вероятность верного предсказания 1 составляет 0.9923 \n",
      "Вероятность верного предсказания 1 составляет 0.9999 \n",
      "Вероятность верного предсказания 0 составляет 0.0439 \n",
      "Вероятность верного предсказания 1 составляет 0.9993 \n",
      "Вероятность верного предсказания 0 составляет 0.9998 \n",
      "Вероятность верного предсказания 1 составляет 0.9755 \n",
      "Вероятность верного предсказания 0 составляет 1.0 \n",
      "Вероятность верного предсказания 0 составляет 0.9999 \n",
      "Вероятность верного предсказания 1 составляет 0.5155 \n",
      "Вероятность верного предсказания 1 составляет 0.9611 \n",
      "Вероятность верного предсказания 0 составляет 0.9001 \n",
      "Вероятность верного предсказания 0 составляет 0.975 \n"
     ]
    }
   ],
   "source": [
    "def get_proba(val, p):\n",
    "    ret = p\n",
    "    if val == 0:\n",
    "        ret = 1 - p\n",
    "    return round(ret, 4)\n",
    "    \n",
    "for val, p in zip(y_test, y_predict):\n",
    "    print(f'Вероятность верного предсказания {val} составляет {get_proba(val, p)} ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
